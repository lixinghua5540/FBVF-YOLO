# A Front-back View Fusion Strategy and A Novel Dataset for Super Tiny Object Detection in Remote Sensing Imageryï¼ˆ2025 KBSï¼‰

è¿™æ˜¯è®ºæ–‡ **ã€ŠA front-back view fusion strategy and a novel dataset for super tiny object detection in remote sensing imageryã€‹** çš„å®˜æ–¹ä»£ç åº“ï¼ŒåŒ…å«RS-STODæ•°æ®é›†ã€è®­ç»ƒã€éªŒè¯ä»£ç 

## æ‘˜è¦
### ä¸­æ–‡ç‰ˆ
è¶…å°å‹ç‰©ä½“ï¼ˆSTOï¼‰çš„ç‰¹å¾å¸¸å¸¸ä¼šæ·¹æ²¡åœ¨é¥æ„Ÿã€è‡ªç„¶å›¾åƒçš„å¤æ‚èƒŒæ™¯ä¸­ï¼Œè¿™ç»™ç°æœ‰çš„åŸºäºå­¦ä¹ çš„ç‰©ä½“æ£€æµ‹æ–¹æ³•å¸¦æ¥äº†å·¨å¤§æŒ‘æˆ˜ã€‚
ç›®å‰ï¼ŒYOLOæ¡†æ¶æ˜¯ç‰©ä½“æ£€æµ‹é¢†åŸŸåº”ç”¨æœ€å¹¿æ³›çš„ä¸»æµæ¡†æ¶ä¹‹ä¸€ï¼Œç„¶è€Œï¼Œå®ƒåœ¨ STOs æ£€æµ‹æ–¹é¢çš„è¡¨ç°ä»æœ‰å¾ˆå¤§çš„æå‡ç©ºé—´ã€‚
å…¶ä¸­ï¼Œæœ€å¤§çš„æŒ‘æˆ˜åœ¨äºç°æœ‰ç½‘ç»œéš¾ä»¥æœ‰æ•ˆæå–STOç¨€ç¼ºçš„å‡ ä½•ã€çº¹ç†å’Œå…‰è°±ä¿¡æ¯ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸YOLOæ¡†æ¶å…¼å®¹çš„å‰åè§†å›¾èåˆï¼ˆFBV-Fusionï¼‰ç­–ç•¥ã€‚
é¦–å…ˆï¼Œä¸ºé˜²æ­¢èƒŒæ™¯ä¿¡æ¯æ·¹æ²¡STOsç‰¹å¾ï¼Œæˆ‘ä»¬é€šè¿‡YOLOéª¨å¹²ç½‘ç»œç”Ÿæˆç›®æ ‡æ©è†œåˆ†æ”¯ï¼Œå°†ç‰¹å¾å±‚åˆ’åˆ†ä¸ºç›®æ ‡å’ŒèƒŒæ™¯åŒºåŸŸã€‚
ç„¶åï¼Œä¸ºäº†æé«˜ç›®æ ‡åŒºåŸŸç‰¹å¾æå–å’ŒèƒŒæ™¯ä¿¡æ¯çš„åˆ©ç”¨ç‡ï¼ŒSkip-Convå–ä»£äº†YOLOé¢ˆéƒ¨çš„æ‰€æœ‰æ™®é€šå·ç§¯ï¼Œé‡ç‚¹å…³æ³¨ç›®æ ‡åŒºåŸŸçš„ç‰¹å¾ã€‚å¹¶ä¸”æˆ‘ä»¬å¢åŠ äº†ç½‘ç»œä¸­ç‰¹å¾å±‚çš„å¤§å°ï¼Œä»¥å‡å°‘æºå¤´ä¿¡æ¯æŸå¤±ã€‚
ä¸ºäº†è¯„ä¼°å…¶æ³›åŒ–èƒ½åŠ›å’ŒFBV-Fusionçš„æœ‰æ•ˆæ€§ï¼Œåœ¨RS-STODã€AI-TODå’ŒTinyPersonä¸Šè¿›è¡Œäº†å®éªŒã€‚ç»“æœè¡¨æ˜ï¼ŒFBV-Fusionä¼˜äºå…¶ä»–SOTAæ–¹æ³•ã€‚åŒæ—¶ï¼ŒFBV-Fusion ç­–ç•¥åœ¨ YOLOv5ã€v7ã€v9ã€v10 å’Œ v11 ä¸­è¿›è¡Œäº†éªŒè¯ï¼Œç»“æœè¡¨æ˜ FBV-Fusion ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„ï¼ˆSOTAï¼‰æ–¹æ³•ã€‚

æ­¤å¤–ï¼Œé’ˆå¯¹é¥æ„Ÿ STOs æ£€æµ‹æ•°æ®é›†çš„ç¨€ç¼ºæ€§å’Œæ ·æœ¬çš„ä¸å¹³è¡¡æ€§ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåä¸ºRS-STODçš„æ–°å‹æ•°æ®é›†ã€‚

![image](https://github.com/lixinghua5540/FBVF-YOLO/blob/master/images/Loss%20of%20feature%20information.png)
<p align="center">éšç€å·ç§¯å±‚æ·±å…¥ï¼Œä¿¡æ¯æŸå¤±é—®é¢˜å‡¸æ˜¾</p>

### è‹±æ–‡ç‰ˆï¼š
æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨é˜…è¯»è‹±æ–‡æ‘˜è¦ï¼Œä»¥ç†è§£æœ¬ç ”ç©¶çš„åŸå§‹æœ¬æ„

Super tiny objects (STOs) are frequently submerged in complex backgrounds of remote sensing and natural images, which brings major challenges for existing learning-based object detection methods. Currently, You Only Look Once (YOLO) is one of the most widely used mainstream methods in the field of object detection. 
However, its performance on STOs detection is still not satisfactory. The biggest challenge lies in the networkâ€™s difficulty in effectively extracting the scarce geometric and spectral information of STOs. Towards this end, a front-back view fusion (FBV-Fusion) strategy compatible with the famous YOLO framework is proposed. Firstly, to prevent background information from overwhelming STOs features, a target mask is generated through the YOLO backbone, dividing the feature layer into target and background regions. 
Then, to enhance the utilization of feature extraction in the target area and background information, the skip convolution replaces all normal convolution in YOLO neck, focusing on the features of the target region. The feature layer size is increased to mitigate the information loss of STOs at the source. Moreover, to address the scarcity of datasets and the imbalance of samples for remote sensing STOs detection, a novel dataset called super tiny object detection for remote sensing (RS-STOD) dataset was constructed. To evaluate its generalization capability and the effectiveness of FBV-Fusion, the experiments were conducted on RS-STOD, AI-TOD and TinyPerson. Meanwhile, the FBV-Fusion strategy was validated across YOLOv5, v7, v9, v10 and v11. The results demonstrate that FBV-Fusion outperforms other state-of-the-art (SOTA) methods.

## æ–¹æ³•æµç¨‹

å…³äºæ­¤éƒ¨åˆ†ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨é˜…è¯»è®ºæ–‡ï¼Œä»¥è·å–å®Œæ•´ä¿¡æ¯

è®ºæ–‡é¢˜ç›®ï¼šA front-back view fusion strategy and a novel dataset for super tiny object detection in remote sensing imagery

![image](https://github.com/lixinghua5540/FBVF-YOLO/blob/master/images/FBV-Fusion%20Framework.jpg)
<p align="center">FBV-Fusionæ€»ä½“æ¡†æ¶</p>

## æ£€æµ‹ç»“æœ

![image](https://github.com/lixinghua5540/FBVF-YOLO/blob/master/images/Methods%20of%20comparison.jpg)
<p align="center">ç›®è§†ç»“æœï¼ˆRS-STODæ•°æ®é›†ï¼‰</p>

![image](https://github.com/lixinghua5540/FBVF-YOLO/blob/master/images/Detail%20of%20the%20result.jpg)
<p align="center">ç»†èŠ‚å±•ç¤ºï¼ˆRS-STODæ•°æ®é›†ï¼‰</p>

![image](https://github.com/lixinghua5540/FBVF-YOLO/blob/master/images/Improved%20YOLO.jpg)
<p align="center">ç²¾åº¦æå‡</p>

## ä»£ç åŠä½¿ç”¨æ–¹æ³•

ä»£ç å­˜å‚¨åœ¨æœ¬å·¥ç¨‹çš„ ***./code*** æ–‡ä»¶å¤¹ä¸‹ï¼Œä½¿ç”¨æ–¹æ³•è§å¯¹åº”çš„å·¥ç¨‹æ–‡ä»¶

ç›®å‰æˆ‘ä»¬ä¸Šä¼ äº†YOLOv5çš„FBV-Fusionç­–ç•¥çš„æ›´æ”¹ç‰ˆï¼ŒYOLOv7ã€v9ã€v10ä¸v11ç‰ˆæœ¬å°†åœ¨ä»£ç æ•´ç†åè¿›è¡Œä¸Šä¼ 

## ckpæ–‡ä»¶

CKPæ–‡ä»¶ä¸‹è½½é“¾æ¥ç»Ÿä¸€å­˜æ”¾åœ¨ ***./checkpoints/README_Chinese.md*** ä¸‹ï¼Œè¯·æŒ‰éœ€ä¸‹è½½ã€‚

æ³¨ï¼šckpæ–‡ä»¶å‡ä¸ºRS-STODæ•°æ®é›†ä¸Šçš„è®­ç»ƒç»“æœï¼Œç”¨äºval

## ğŸ“„ å¼•ç”¨æ ¼å¼

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬ç ”ç©¶çš„ä»£ç æˆ–æ•°æ®é›†ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å¼•ç”¨ï¼š

<pre> bibtex 
  @article{BAI2025114051, 
  title = {A front-back view fusion strategy and a novel dataset for super tiny object detection in remote sensing imagery}, 
  author = {Xuechen Bai and Xinghua Li and Jianhao Miao and Huanfeng Shen}, 
  journal = {Knowledge-Based Systems},
  volume = {326}, 
  pages = {114051}, 
  year = {2025}, 
  doi = {https://doi.org/10.1016/j.knosys.2025.114051}, 
  }  </pre>
